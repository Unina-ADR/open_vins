<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Getting Started &raquo; Supported Datasets | OpenVINS</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400i,600,600i%7CSource+Code+Pro:400,400i,600&amp;subset=latin-ext" />
  <link rel="stylesheet" href="m-udel+documentation.compiled.css" />
  <link rel="stylesheet" href="custom.css" />
  <link rel="icon" href="favicon-light.png" type="image/png" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#2f73a3" />
</head>
<body>
<header><nav id="navigation">
  <div class="m-container">
    <div class="m-row">
      <a href="index.html" id="m-navbar-brand" class="m-col-t-8 m-col-m-none m-left-m">OpenVINS</a>
      <div class="m-col-t-4 m-hide-m m-text-right m-nopadr">
        <a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
          <path id="m-doc-search-icon-path" d="m6 0c-3.31 0-6 2.69-6 6 0 3.31 2.69 6 6 6 1.49 0 2.85-0.541 3.89-1.44-0.0164 0.338 0.147 0.759 0.5 1.15l3.22 3.79c0.552 0.614 1.45 0.665 2 0.115 0.55-0.55 0.499-1.45-0.115-2l-3.79-3.22c-0.392-0.353-0.812-0.515-1.15-0.5 0.895-1.05 1.44-2.41 1.44-3.89 0-3.31-2.69-6-6-6zm0 1.56a4.44 4.44 0 0 1 4.44 4.44 4.44 4.44 0 0 1-4.44 4.44 4.44 4.44 0 0 1-4.44-4.44 4.44 4.44 0 0 1 4.44-4.44z"/>
        </svg></a>
        <a id="m-navbar-show" href="#navigation" title="Show navigation"></a>
        <a id="m-navbar-hide" href="#" title="Hide navigation"></a>
      </div>
      <div id="m-navbar-collapse" class="m-col-t-12 m-show-m m-col-m-none m-right-m">
        <div class="m-row">
          <ol class="m-col-t-6 m-col-m-none">
            <li><a href="pages.html">Pages</a></li>
            <li><a href="annotated.html">Classes</a></li>
            <li><a href="namespaceov__core.html">ov_core</a></li>
            <li><a href="namespaceov__type.html">ov_type</a></li>
            <li><a href="namespaceov__msckf.html">ov_msckf</a></li>
            <li><a href="namespaceov__init.html">ov_init</a></li>
            <li><a href="namespaceov__eval.html">ov_eval</a></li>
          </ol>
          <ol class="m-col-t-6 m-col-m-none" start="8">
            <li><a href="https://github.com/rpng/open_vins/">GitHub</a></li>
            <li class="m-show-m"><a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
              <use href="#m-doc-search-icon-path" />
            </svg></a></li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</nav></header>
<main><article>
  <div class="m-container m-container-inflatable">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <h1>
          <span class="m-breadcrumb"><a href="getting-started.html">Getting Started</a> &raquo;</span>
          Supported Datasets
        </h1>
        <div class="m-block m-default">
          <h3>Contents</h3>
          <ul>
            <li><a href="#gs-data-euroc">The EuRoC MAV Dataset</a></li>
            <li><a href="#gs-data-tumvi">TUM Visual-Inertial Dataset</a></li>
            <li><a href="#gs-data-rpng-ar-table">RPNG AR Table Dataset</a></li>
            <li><a href="#gs-data-rpng">RPNG OpenVINS Dataset</a></li>
            <li><a href="#gs-data-uzhfpv">UZH-FPV Drone Racing Dataset</a></li>
            <li><a href="#gs-data-kaist">KAIST Urban Dataset</a></li>
            <li><a href="#gs-data-kaist-vio">KAIST VIO Dataset</a></li>
          </ul>
        </div>
<section id="gs-data-euroc"><h2><a href="#gs-data-euroc">The EuRoC MAV Dataset</a></h2><p>The ETH ASL <a href="https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets">EuRoC MAV dataset</a> <a href="citelist.html#CITEREF_Burri2016IJRR" class="m-doc">[4]</a> is one of the most used datasets in the visual-inertial / simultaneous localization and mapping (SLAM) research literature. The reason for this is the synchronised inertial+camera sensor data and the high quality groundtruth. The dataset contains different sequences of varying difficulty of a Micro Aerial Vehicle (MAV) flying in an indoor room. Monochrome stereo images are collected by a two Aptina MT9V034 global shutter cameras at 20 frames per seconds, while a ADIS16448 MEMS inertial unit provides linear accelerations and angular velocities at a rate of 200 samples per second.</p><p>We recommend that most users start testing on this dataset before moving on to the other datasets that our system support or before trying with your own collected data. The machine hall datasets have the MAV being picked up in the beginning and then set down, we normally skip this part, but it should be able to be handled by the filter if SLAM features are enabled. Please take a look at the <a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/scripts/run_ros_eth.sh">run_<wbr />ros_<wbr />eth.sh</a> script for some reasonable default values (they might still need to be tuned).</p><aside class="m-block m-warning"><h3>Groundtruth on V1_01_easy</h3><p>We have found that the groundtruth on the V1_01_easy dataset is not accurate in its orientation estimate. We have recomputed this by optimizing the inertial and vicon readings in a graph to get the trajectory of the imu (refer to our <a href="https://github.com/rpng/vicon2gt">vicon2gt</a> <a href="citelist.html#CITEREF_Geneva2020TRVICON2GT" class="m-doc">[16]</a> project). You can find the output at this <a href="https://drive.google.com/drive/folders/1GospxhpVnyzvJNVUdN4qyrl8GlOd7vw8?usp=drive_link">link</a> and is what we normally use to evaluate the error on this dataset.</p></aside><div class="m-text-center"><table class="m-table"><thead><tr><th>Dataset Name</th><th>Length (m)</th><th>Dataset Link</th><th>Groundtruth Traj.</th><th>Config</th></tr></thead><tbody><tr><td>Vicon Room 1 01</td><td>58</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_01_easy/V1_01_easy.bag">rosbag</a>, <a href="https://drive.google.com/file/d/1LFrdiMU6UBjtFfXPHzjJ4L7iDIXcdhvh/view?usp=drive_link">rosbag2</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/euroc_mav">config</a></td></tr><tr><td>Vicon Room 1 02</td><td>76</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_02_medium/V1_02_medium.bag">rosbag</a> , <a href="https://drive.google.com/file/d/1rlGSy7h38ucm8jr8ssH-sJPX84JfkBtX/view?usp=drive_link">rosbag2</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/euroc_mav">config</a></td></tr><tr><td>Vicon Room 1 03</td><td>79</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_03_difficult/V1_03_difficult.bag">rosbag</a>, <a href="https://drive.google.com/file/d/1Gy1zc4LaMlwsLpXBqOIci6Y3cV_5r-0k/view?usp=drive_link">rosbag2</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/euroc_mav">config</a></td></tr><tr><td>Vicon Room 2 01</td><td>37</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room2/V2_01_easy/V2_01_easy.bag">rosbag</a>, <a href="https://drive.google.com/file/d/1KAkE8Ptq3eSQlXMozJgzNIAVUBH3h0FP/view?usp=drive_link">rosbag2</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/euroc_mav">config</a></td></tr><tr><td>Vicon Room 2 02</td><td>83</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room2/V2_02_medium/V2_02_medium.bag">rosbag</a>, <a href="https://drive.google.com/file/d/1Gj4psmvcAwYwCp4T4CQH-d2ZVJ09d3x2/view?usp=drive_link">rosbag2</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/euroc_mav">config</a></td></tr><tr><td>Vicon Room 2 03</td><td>86</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room2/V2_03_difficult/V2_03_difficult.bag">rosbag</a>, <a href="https://drive.google.com/file/d/1ohWd0JqDvVhTqjOS5MqHafit5MPdlbff/view?usp=drive_link">rosbag2</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/euroc_mav">config</a></td></tr><tr><td>Machine Hall 01</td><td>80</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/machine_hall/MH_01_easy/MH_01_easy.bag">rosbag</a>, <a href="https://drive.google.com/file/d/1UP4nkuSEOQECZTswwh9BPgfMl-dnDstA/view?usp=drive_link">rosbag2</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/euroc_mav">config</a></td></tr><tr><td>Machine Hall 02</td><td>73</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/machine_hall/MH_02_easy/MH_02_easy.bag">rosbag</a>, <a href="https://drive.google.com/file/d/1wWZgZCqYz6zzzTXS0iqvQCP-cWfFuGLK/view?usp=drive_link">rosbag2</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/euroc_mav">config</a></td></tr><tr><td>Machine Hall 03</td><td>131</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/machine_hall/MH_03_medium/MH_03_medium.bag">rosbag</a>, <a href="https://drive.google.com/file/d/1er07gZ8rso8R3Su00hJMm_GZ4z1n9Rpq/view?usp=drive_link">rosbag2</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/euroc_mav">config</a></td></tr><tr><td>Machine Hall 04</td><td>92</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/machine_hall/MH_04_difficult/MH_04_difficult.bag">rosbag</a>, <a href="https://drive.google.com/file/d/1eC8joRXo1rh0wzOpq3e-B4dQ8-w6wZYz/view?usp=drive_link">rosbag2</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/euroc_mav">config</a></td></tr><tr><td>Machine Hall 05</td><td>98</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/machine_hall/MH_05_difficult/MH_05_difficult.bag">rosbag</a>, <a href="https://drive.google.com/file/d/1zoN94K1Afrp7HXSduRLkJBiEjPKdk1UA/view?usp=drive_link">rosbag2</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/euroc_mav">config</a></td></tr></tbody></table></div></section><section id="gs-data-tumvi"><h2><a href="#gs-data-tumvi">TUM Visual-Inertial Dataset</a></h2><p>The TUM <a href="https://vision.in.tum.de/data/datasets/visual-inertial-dataset">Visual-Inertial Dataset</a> <a href="citelist.html#CITEREF_Schubert2018IROS" class="m-doc">[39]</a> is a more recent dataset that was presented to provide a way to evaluate state-of-the-art visual inertial odometry approaches. As compared to the EuRoC MAV datasets, this dataset provides photometric calibration of the cameras which has not been available in any other visual-inertal dataset for researchers. Monochrome stereo images are collected by two IDS uEye UI-3241LE-M-GL global shutter cameras at 20 frames per second, while a Bosch BMI160 inertial unit provides linear accelerations and angular velocities at a rate of 200 samples per second. Not all datasets have groundtruth available throughout the entire trajectory as the motion capture system is limited to the starting and ending room. There are quite a few very challenging outdoor handheld datasets which are a challenging direction for research. Note that we focus on the room datasets as full 6 dof pose collection is available over the total trajectory.</p><img class="m-image" src="tumvi.png" alt="Image" style="width: 90%;" /><aside class="m-block m-warning"><h3>Filter Initialization from Standstill</h3><p>These datasets have very non-static starts, as they are handheld, and the standstill initialization has issues handling this. Thus careful tuning of the imu initialization threshold is typically needed to ensure that the initialized orientation and the zero velocity assumption are valid. Please take a look at the <a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/scripts/run_ros_tumvi.sh">run_<wbr />ros_<wbr />tumvi.sh</a> script for some reasonable default values (they might still need to be tuned). One can enable dynamic initialization to avoid this problem via the <code>init_dyn_use</code> configuration value.</p></aside><div class="m-text-center"><table class="m-table"><thead><tr><th>Dataset Name</th><th>Length (m)</th><th>Dataset Link</th><th>Groundtruth Traj.</th><th>Config</th></tr></thead><tbody><tr><td>room1</td><td>147</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room1_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/tum_vi">config</a></td></tr><tr><td>room2</td><td>142</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room2_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/tum_vi">config</a></td></tr><tr><td>room3</td><td>136</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room3_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/tum_vi">config</a></td></tr><tr><td>room4</td><td>69</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room4_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/tum_vi">config</a></td></tr><tr><td>room5</td><td>132</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room5_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/tum_vi">config</a></td></tr><tr><td>room6</td><td>67</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room6_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/tum_vi">config</a></td></tr></tbody></table></div></section><section id="gs-data-rpng-ar-table"><h2><a href="#gs-data-rpng-ar-table">RPNG AR Table Dataset</a></h2><p>The <a href="https://github.com/rpng/ar_table_dataset/">Indoor AR Table Visual-Inertial Datasets</a> <a href="citelist.html#CITEREF_Chen2023ICRA" class="m-doc">[7]</a> were collected to demonstrate the impact of estimating long-term planar surfaces within a visual-inertial estimator. An Intel Realsense D4553 with 30Hz RGB-D (depth was not used) and 400Hz BMI055 IMU along with 100Hz OptiTrack poses were recorded in 1-2 minute segments. The groundtruth was recovered using the <a href="https://github.com/rpng/vicon2gt">vicon2gt</a> utility <a href="citelist.html#CITEREF_Geneva2020TRVICON2GT" class="m-doc">[16]</a>.</p><img class="m-image" src="ar_table.jpg" alt="Image" style="width: 90%;" /><div class="m-text-center"><table class="m-table"><thead><tr><th>Dataset Name</th><th>Length (m)</th><th>Dataset Link</th><th>Size (GB)</th><th>Groundtruth Traj.</th><th>Config</th></tr></thead><tbody><tr><td>table1</td><td>56</td><td><a href="https://drive.google.com/file/d/1qpjOQQYB8rvozTTbGBvuWjiat9MlDaMi/view?usp=sharing">rosbag</a></td><td>4.77</td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/rpng_plane">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_plane">config</a></td></tr><tr><td>table2</td><td>44</td><td><a href="https://drive.google.com/file/d/1RBt8xYDsegtRiY5gKVyg9WPhecVvdXqn/view?usp=sharing">rosbag</a></td><td>5.54</td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/rpng_plane">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_plane">config</a></td></tr><tr><td>table3</td><td>88</td><td><a href="https://drive.google.com/file/d/1_uLTYC3i2b1tx85OpGlqecxXgaO7BDT_/view?usp=sharing">rosbag</a></td><td>13.19</td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/rpng_plane">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_plane">config</a></td></tr><tr><td>table4</td><td>91</td><td><a href="https://drive.google.com/file/d/1nYno_ttjGHwCQoxgV5SisVTc19Cb5O5c/view?usp=sharing">rosbag</a></td><td>11.49</td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/rpng_plane">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_plane">config</a></td></tr><tr><td>table5</td><td>75</td><td><a href="https://drive.google.com/file/d/1CjkGfSCD_hWAidKsJ7edhuWQg7CyGa3U/view?usp=sharing">rosbag</a></td><td>11.66</td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/rpng_plane">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_plane">config</a></td></tr><tr><td>table6</td><td>50</td><td><a href="https://drive.google.com/file/d/1FAGk7ZjRKDTkf-lhW3sb4EPj6SsUhyeQ/view?usp=sharing">rosbag</a></td><td>5.26</td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/rpng_plane">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_plane">config</a></td></tr><tr><td>table7</td><td>63</td><td><a href="https://drive.google.com/file/d/1yWZGo6N0qlP_fHMIsr0jayRP3tXCO54U/view?usp=sharing">rosbag</a></td><td>9.02</td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/rpng_plane">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_plane">config</a></td></tr><tr><td>table8</td><td>125</td><td><a href="https://drive.google.com/file/d/1pIz9owK4PvIkL_1t6eTZwGMrsLNpHBwa/view?usp=sharing">rosbag</a></td><td>16.01</td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/rpng_plane">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_plane">config</a></td></tr></tbody></table></div></section><section id="gs-data-rpng"><h2><a href="#gs-data-rpng">RPNG OpenVINS Dataset</a></h2><p>In additional the community maintained datasets, we have also released a few datasets. Please cite the OpenVINS paper if you use any of these datasets in your works. Here are the specifics of the sensors that each dataset uses:</p><ul><li>ArUco Datasets:<ul><li>Core visual-inertial sensor is the <a href="https://furgalep.github.io/bib/nikolic_icra14.pdf">VI-Sensor</a></li><li>Stereo global shutter images at 20 Hz</li><li>ADIS16448 IMU at 200 Hz</li><li>Kalibr calibration file can be found <a href="https://drive.google.com/file/d/1eYymZIMZhvH80O3ae7NSNT_KOhKkuB7q/view?usp=drive_link">here</a></li></ul></li><li>Ironsides Datasets:<ul><li>Core visual-inertial sensor is the <a href="https://arxiv.org/pdf/1710.00893v1.pdf">ironsides</a></li><li>Has two <a href="https://docs.emlid.com/reach/">Reach RTK</a> one subscribed to a base station for corrections</li><li>Stereo global shutter fisheye images at 20 Hz</li><li>InvenSense IMU at 200 Hz</li><li>GPS fixes at 5 Hz (/reach01/tcpfix has corrections from <a href="https://cors.dot.ny.gov/sbc">NYSNet</a>)</li><li>Kalibr calibration file can be found <a href="https://drive.google.com/file/d/1N-DfxBDxEIiO_k6WbVaxZVViwplVJJY1/view?usp=drive_link">here</a></li></ul></li></ul><img class="m-image" src="neighborhood.png" alt="Image" style="width: 90%;" /><aside class="m-block m-warning"><h3>Monocular Camera</h3><p>Currently there are issues with running with a monocular camera on the Ironside Neighborhood car datasets. This is likely due to the near-constant velocity and &quot;smoothness&quot; of the trajectory. Please refer to <a href="citelist.html#CITEREF_Lee2020IROS" class="m-doc">[25]</a> and <a href="citelist.html#CITEREF_Wu2017ICRA" class="m-doc">[42]</a> for details.</p></aside><p>Most of these datasets do not have perfect calibration parameters, and some are not time synchronised. Thus, please ensure that you have enabled online calibration of these parameters. Additionally, there is no groundtruth for these datasets, but some do include GPS messages if you wish to compare relative to something.</p><div class="m-text-center"><table class="m-table"><thead><tr><th>Dataset Name</th><th>Length (m)</th><th>Dataset Link</th><th>Groundtruth Traj.</th><th>Config</th></tr></thead><tbody><tr><td>ArUco Room 01</td><td>27</td><td><a href="https://drive.google.com/file/d/1DnVPafN3qeyuf0nESCk7gGXnhTgEcOlT/view?usp=drive_link">rosbag</a></td><td>none</td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_aruco">config aruco</a></td></tr><tr><td>ArUco Room 02</td><td>93</td><td><a href="https://drive.google.com/file/d/1_ektsxj1UvZ51ZEs9zPEKL7x4kZtcgbg/view?usp=drive_link">rosbag</a></td><td>none</td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_aruco">config aruco</a></td></tr><tr><td>ArUco Hallway 01</td><td>190</td><td><a href="https://drive.google.com/file/d/1JLvy6zBgGCkRUTd0Bo14vJVYuVxpZ3ix/view?usp=drive_link">rosbag</a></td><td>none</td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_aruco">config aruco</a></td></tr><tr><td>ArUco Hallway 02</td><td>105</td><td><a href="https://drive.google.com/file/d/1GQiyVLIimGjX3LEFD5kptGHbLTiOypuL/view?usp=drive_link">rosbag</a></td><td>none</td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_aruco">config aruco</a></td></tr><tr><td>Neighborhood 01</td><td>2300</td><td><a href="https://drive.google.com/file/d/1JAWpTE_tqs__XYa_906JgFy9CeZ1KccO/view?usp=drive_link">rosbag</a></td><td>none</td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_ironsides">config ironsides</a></td></tr><tr><td>Neighborhood 02</td><td>7400</td><td><a href="https://drive.google.com/file/d/1WmCigwqq-eOa6nOqjzF5m3J4VTw_sVIu/view?usp=drive_link">rosbag</a></td><td>none</td><td><a href="https://github.com/rpng/open_vins/blob/master/config/rpng_ironsides">config ironsides</a></td></tr></tbody></table></div></section><section id="gs-data-uzhfpv"><h2><a href="#gs-data-uzhfpv">UZH-FPV Drone Racing Dataset</a></h2><p>The <a href="https://fpv.ifi.uzh.ch/">UZH-FPV Drone Racing Dataset</a> <a href="citelist.html#CITEREF_Schubert2018IROS" class="m-doc">[39]</a> is a dataset focused on high-speed agressive 6dof motion with very high levels of optical flow as compared to other datasets. A FPV drone racing quadrotor has on board a Qualcomm Snapdragon Flight board which can provide inertial measurement and has two 640x480 grayscale global shutter fisheye camera&#x27;s attached. The groundtruth is collected with a Leica Nova MS60 laser tracker. There are four total sensor configurations and calibration provides including: indoor forward facing stereo, indoor 45 degree stereo, outdoor forward facing, and outdoor 45 degree. A top speed of 12.8 m/s (28 mph) is reached in the indoor scenarios, and 23.4 m/s (54 mphs) is reached in the outdoor datasets. Each of these datasets is picked up in the beginning and then set down, we normally skip this part, but it should be able to be handled by the filter if SLAM features are enabled. Please take a look at the <a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/scripts/run_ros_uzhfpv.sh">run_<wbr />ros_<wbr />uzhfpv.sh</a> script for some reasonable default values (they might still need to be tuned).</p><img class="m-image" src="uzhfpv.png" alt="Image" style="width: 90%;" /><aside class="m-block m-warning"><h3>Dataset Groundtruthing</h3><p>Only the Absolute Trajectory Error (ATE) should be used as a metric for this dataset. This is due to inaccurate groundtruth orientation estimates which are explain in their <a href="https://fpv.ifi.uzh.ch/wp-content/uploads/2020/11/Ground-Truth-Rotation-Issue-Report.pdf">report</a> on the issue. The basic summary is that it is hard to get an accurate orientation information due to the point-based Leica measurements used to groundtruth.</p></aside><div class="m-text-center"><table class="m-table"><thead><tr><th>Dataset Name</th><th>Length (m)</th><th>Dataset Link</th><th>Groundtruth Traj.</th><th>Config</th></tr></thead><tbody><tr><td>Indoor 5</td><td>157</td><td><a href="http://rpg.ifi.uzh.ch/datasets/uzh-fpv-newer-versions/v2/indoor_forward_5_snapdragon_with_gt.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/uzh_fpv">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/uzhfpv_indoor">config</a></td></tr><tr><td>Indoor 6</td><td>204</td><td><a href="http://rpg.ifi.uzh.ch/datasets/uzh-fpv-newer-versions/v2/indoor_forward_6_snapdragon_with_gt.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/uzh_fpv">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/uzhfpv_indoor">config</a></td></tr><tr><td>Indoor 7</td><td>314</td><td><a href="http://rpg.ifi.uzh.ch/datasets/uzh-fpv-newer-versions/v2/indoor_forward_7_snapdragon_with_gt.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/uzh_fpv">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/uzhfpv_indoor">config</a></td></tr><tr><td>Indoor 9</td><td>136</td><td><a href="http://rpg.ifi.uzh.ch/datasets/uzh-fpv-newer-versions/v2/indoor_forward_9_snapdragon_with_gt.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/uzh_fpv">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/uzhfpv_indoor">config</a></td></tr><tr><td>Indoor 10</td><td>129</td><td><a href="http://rpg.ifi.uzh.ch/datasets/uzh-fpv-newer-versions/v2/indoor_forward_10_snapdragon_with_gt.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/uzh_fpv">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/uzhfpv_indoor">config</a></td></tr><tr><td>Indoor 45deg 2</td><td>207</td><td><a href="http://rpg.ifi.uzh.ch/datasets/uzh-fpv-newer-versions/v2/indoor_45_2_snapdragon_with_gt.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/uzh_fpv">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/uzhfpv_indoor_45">config</a></td></tr><tr><td>Indoor 45deg 4</td><td>164</td><td><a href="http://rpg.ifi.uzh.ch/datasets/uzh-fpv-newer-versions/v2/indoor_45_4_snapdragon_with_gt.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/uzh_fpv">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/uzhfpv_indoor_45">config</a></td></tr><tr><td>Indoor 45deg 12</td><td>112</td><td><a href="http://rpg.ifi.uzh.ch/datasets/uzh-fpv-newer-versions/v2/indoor_45_12_snapdragon_with_gt.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/uzh_fpv">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/uzhfpv_indoor_45">config</a></td></tr><tr><td>Indoor 45deg 13</td><td>159</td><td><a href="http://rpg.ifi.uzh.ch/datasets/uzh-fpv-newer-versions/v2/indoor_45_13_snapdragon_with_gt.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/uzh_fpv">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/uzhfpv_indoor_45">config</a></td></tr><tr><td>Indoor 45deg 14</td><td>211</td><td><a href="http://rpg.ifi.uzh.ch/datasets/uzh-fpv-newer-versions/v2/indoor_45_14_snapdragon_with_gt.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/uzh_fpv">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/uzhfpv_indoor_45">config</a></td></tr></tbody></table></div></section><section id="gs-data-kaist"><h2><a href="#gs-data-kaist">KAIST Urban Dataset</a></h2><p>The <a href="https://sites.google.com/view/complex-urban-dataset">KAIST urban dataset</a> <a href="citelist.html#CITEREF_Jeong2019IJRR" class="m-doc">[23]</a> is a dataset focus on autonomous driving and localization in challenging complex urban environments. The dataset was collected in Korea with a vehicle equipped with stereo camera pair, 2d SICK LiDARs, 3d Velodyne LiDAR, Xsens IMU, fiber optic gyro (FoG), wheel encoders, and RKT GPS. The camera is 10 Hz, while the Xsens IMU is 100 Hz sensing rate. A groundtruth &quot;baseline&quot; trajectory is also provided which is the resulting output from fusion of the FoG, RKT GPS, and wheel encoders. We provide <a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist/matlab">processing scripts</a> to generate the calibration and groundtruth from the dataset&#x27;s formats.</p><aside class="m-block m-warning"><h3>Dynamic Environments</h3><p>A challenging open research question is being able to handle dynamic objects seen from the cameras. By default we rely on our tracking 8 point RANSAC to handle these dynamics objects. In the most of the KAIST datasets the majority of the scene can be taken up by other moving vehicles, thus the performance can suffer. Please be aware of this fact.</p></aside><p>We recommend converting the KAIST file format into a ROS bag format. If you are using ROS2 then you should first convert into a ROS1 then convert following the <a href="dev-ros1-to-ros2.html" class="m-doc">ROS1 to ROS2 Bag Conversion Guide</a> . Follow the instructions on the <a href="https://github.com/rpng/kaist2bag">kaist2bag</a> repository:</p><pre class="m-console"><span class="go">git clone https://github.com/irapkaist/irp_sen_msgs.git</span>
<span class="go">git clone https://github.com/rpng/kaist2bag.git</span></pre><aside class="m-block m-warning"><h3>Monocular Camera</h3><p>Currently there are issues with running with a monocular camera on this dataset. This is likely due to the near-constant velocity and &quot;smoothness&quot; of the trajectory. Please refer to <a href="citelist.html#CITEREF_Lee2020IROS" class="m-doc">[25]</a> and <a href="citelist.html#CITEREF_Wu2017ICRA" class="m-doc">[42]</a> for details.</p></aside><p>You can also try to use the <a href="https://github.com/irapkaist/file_player">file_<wbr />player</a> to publish live. It is important to <em>disable</em> the &quot;skip stop section&quot; to ensure that we have continuous sensor feeds. Typically we process the datasets at 1.5x rate so we get a ~20 Hz image feed and the datasets can be processed in a more efficient manor.</p><div class="m-text-center"><table class="m-table"><thead><tr><th>Dataset Name</th><th>Length (km)</th><th>Dataset Link</th><th>Groundtruth Traj.</th><th>Example Launch</th></tr></thead><tbody><tr><td>Urban 28</td><td>11.47</td><td><a href="https://sites.google.com/view/complex-urban-dataset/download-lidar-stereo?authuser=0">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist">config</a></td></tr><tr><td>Urban 32</td><td>7.30</td><td><a href="https://sites.google.com/view/complex-urban-dataset/download-lidar-stereo?authuser=0">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist">config</a></td></tr><tr><td>Urban 38</td><td>11.42</td><td><a href="https://sites.google.com/view/complex-urban-dataset/download-lidar-stereo?authuser=0">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist">config</a></td></tr><tr><td>Urban 39</td><td>11.06</td><td><a href="https://sites.google.com/view/complex-urban-dataset/download-lidar-stereo?authuser=0">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist">config</a></td></tr></tbody></table></div></section><section id="gs-data-kaist-vio"><h2><a href="#gs-data-kaist-vio">KAIST VIO Dataset</a></h2><p>The <a href="https://github.com/url-kaist/kaistviodataset">KAIST VIO dataset</a> <a href="citelist.html#CITEREF_Jeon2021RAL" class="m-doc">[22]</a> is a dataset of a MAV in an indoor 3.15 x 3.60 x 2.50 meter environment which undergoes various trajectory motions. The camera is intel realsense D435i 25 Hz, while the IMU is 100 Hz sensing rate from the pixelhawk 4 unit. A groundtruth &quot;baseline&quot; trajectory is also provided from a OptiTrack Mocap system at 50 Hz, the bag files have the marker body frame to IMU frame already applied. This topic has been provided in ov_data for convenience sake.</p><div class="m-text-center"><table class="m-table"><thead><tr><th>Dataset Name</th><th>Length (km)</th><th>Dataset Link</th><th>Groundtruth Traj.</th><th>Example Launch</th></tr></thead><tbody><tr><td>circle</td><td>29.99</td><td><a href="https://urserver.kaist.ac.kr/publicdata/KAIST_VIO_Dataset/circle/circle.bag">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist_vio">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist_vio">config</a></td></tr><tr><td>circle_fast</td><td>64.15</td><td><a href="https://urserver.kaist.ac.kr/publicdata/KAIST_VIO_Dataset/circle/circle_fast.bag">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist_vio">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist_vio">config</a></td></tr><tr><td>circle_head</td><td>35.05</td><td><a href="https://urserver.kaist.ac.kr/publicdata/KAIST_VIO_Dataset/circle/circle_head.bag">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist_vio">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist_vio">config</a></td></tr><tr><td>infinite</td><td>29.35</td><td><a href="https://urserver.kaist.ac.kr/publicdata/KAIST_VIO_Dataset/infinite/infinite.bag">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist_vio">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist_vio">config</a></td></tr><tr><td>infinite_fast</td><td>54.24</td><td><a href="https://urserver.kaist.ac.kr/publicdata/KAIST_VIO_Dataset/infinite/infinite_fast.bag">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist_vio">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist_vio">config</a></td></tr><tr><td>infinite_head</td><td>37.45</td><td><a href="https://urserver.kaist.ac.kr/publicdata/KAIST_VIO_Dataset/infinite/infinite_head.bag">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist_vio">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist_vio">config</a></td></tr><tr><td>rotation</td><td>7.82</td><td><a href="https://urserver.kaist.ac.kr/publicdata/KAIST_VIO_Dataset/rotation/rotation.bag">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist_vio">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist_vio">config</a></td></tr><tr><td>rotation_fast</td><td>14.55</td><td><a href="https://urserver.kaist.ac.kr/publicdata/KAIST_VIO_Dataset/rotation/rotation_fast.bag">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist_vio">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist_vio">config</a></td></tr><tr><td>square</td><td>41.94</td><td><a href="https://urserver.kaist.ac.kr/publicdata/KAIST_VIO_Dataset/square/square.bag">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist_vio">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist_vio">config</a></td></tr><tr><td>square_fast</td><td>44.07</td><td><a href="https://urserver.kaist.ac.kr/publicdata/KAIST_VIO_Dataset/square/square_fast.bag">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist_vio">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist_vio">config</a></td></tr><tr><td>square_head</td><td>50.00</td><td><a href="https://urserver.kaist.ac.kr/publicdata/KAIST_VIO_Dataset/square/square_head.bag">download</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/kaist_vio">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/config/kaist_vio">config</a></td></tr></tbody></table></div></section>
      </div>
    </div>
  </div>
</article></main>
<div class="m-doc-search" id="search">
  <a href="#!" onclick="return hideSearch()"></a>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-m-8 m-push-m-2">
        <div class="m-doc-search-header m-text m-small">
          <div><span class="m-label m-default">Tab</span> / <span class="m-label m-default">T</span> to search, <span class="m-label m-default">Esc</span> to close</div>
          <div id="search-symbolcount">&hellip;</div>
        </div>
        <div class="m-doc-search-content">
          <form>
            <input type="search" name="q" id="search-input" placeholder="Loading &hellip;" disabled="disabled" autofocus="autofocus" autocomplete="off" spellcheck="false" />
          </form>
          <noscript class="m-text m-danger m-text-center">Unlike everything else in the docs, the search functionality <em>requires</em> JavaScript.</noscript>
          <div id="search-help" class="m-text m-dim m-text-center">
            <p class="m-noindent">Search for symbols, directories, files, pages or
            modules. You can omit any prefix from the symbol or file path; adding a
            <code>:</code> or <code>/</code> suffix lists all members of given symbol or
            directory.</p>
            <p class="m-noindent">Use <span class="m-label m-dim">&darr;</span>
            / <span class="m-label m-dim">&uarr;</span> to navigate through the list,
            <span class="m-label m-dim">Enter</span> to go.
            <span class="m-label m-dim">Tab</span> autocompletes common prefix, you can
            copy a link to the result using <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">L</span> while <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">M</span> produces a Markdown link.</p>
          </div>
          <div id="search-notfound" class="m-text m-warning m-text-center">Sorry, nothing was found.</div>
          <ul id="search-results"></ul>
        </div>
      </div>
    </div>
  </div>
</div>
<script src="search-v1.js"></script>
<script src="searchdata-v1.js" async="async"></script>
<footer><nav>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <p>Generated by <a href="https://doxygen.org/">Doxygen</a> 1.8.20 and <a href="https://mcss.mosra.cz/">m.css</a>.</p>
      </div>
    </div>
  </div>
</nav></footer>
</body>
</html>
